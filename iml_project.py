# -*- coding: utf-8 -*-
"""IML_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mfj0Kgtlo9ocR0yyDlnnDO5gtu6a0kn4

# Introduction To Machine Learning
# CSL 2010
# Project

# Mobile price prediction and explainability
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

"""

**1.  Data Familiarization**


"""

from google.colab import drive
drive.mount('/content/drive')

cell_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Cellphone.csv')

cell_data.head(10)

print(f'Shape of dataframe: {cell_data.shape}')

cell_data.info()

cell_data.describe()

"""**2.  Data Preprocessing**

Check for missing values
"""

missing_values = cell_data.isnull().sum()
print("Missing Values:")
print(f"no of missing values in data are {missing_values}")

print("-------------------------------------------------------")

print(f"Tota no of missing values are {missing_values.sum()}")

"""Check for duplicate rows"""

duplicates = cell_data.duplicated().sum()
print("Duplicate Rows:", duplicates)

"""**3.   Exploratory Data Analysis (EDA)**

Distribution of numerical features
"""

plt.figure(figsize=(13, 6))
numerical_cols = ['Price', 'Sale', 'weight', 'resoloution', 'ppi', 'cpu freq', 'internal mem', 'ram', 'RearCam', 'Front_Cam', 'battery', 'thickness']
for col in numerical_cols:
    plt.hist(cell_data[col], bins=20)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

"""**Correlation Matrix**"""

corr = cell_data.corr()
np.fill_diagonal(corr.values, 1)
corr

"""*Correlation between variables visualized with sns.heatmap*"""

plt.figure(figsize=(20,10))
sns.heatmap(corr, annot=True, cmap='Blues')

corr.unstack().sort_values(kind='quicksort', na_position='first').drop_duplicates(keep='last')

"""Very high correlation between "Price" and "ram" -- this means that we should use the ram variable in predicting the price range of a mobile phone when doing our Machine Learning prediction

Display highest correlations between price_range and the other features in our dataset
"""

corr.abs()['Price'].sort_values(ascending=False)

"""The highest correlations to our target variable (Price) are:



1.   ram
2.   ppi
3.   internal mem
4.   RearCam

**Key Variables Visualizations**
"""

variance = cell_data.drop('Price', axis = 1).var()

plt.figure(figsize=(8, 6))
variance.plot(kind='bar', color='blue')
plt.title('Variance of Features')
plt.xlabel('Features')
plt.ylabel('Variance')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

sns.displot(cell_data, x='ram')

sns.lmplot(x='ram', y='Price', data=cell_data, line_kws={'color': 'purple'})
plt.yticks([0, 1000, 2000, 3000, 4000, 5000])
plt.xlabel('Ram')
plt.ylabel('Price Range')
plt.show()

"""The plot aboves shows the high correlation between ram and price range. It shows the general pattern: as ram increases, mobile's price increases"""

n_cores = cell_data['cpu core'].value_counts()
plt.title('Number of cpu cores in cell phones\n\n', weight='bold')
n_cores.plot.pie(autopct="%.1f%%", radius=1.5)
plt.show()

"""Next, we'll use plotly to visualize the 3 most highly correlated variables to price_range"""

import plotly.express as px
fig = px.scatter_3d(cell_data.head(1000), x='ram', y='ppi', z='internal mem', color='Price')
fig.show()

"""Above, we see how ram, ppi , and internal memory all contribute to a mobile phone's price classification"""

# scatter plot for Sale vs. Front_Cam
plt.figure(figsize=(10, 5))
plt.scatter(cell_data['Front_Cam'], cell_data['Sale'], color='blue', label='Front Cam')
plt.title('Sale vs. Front Cam')
plt.xlabel('Front Cam')
plt.ylabel('Sale')
plt.legend()
plt.grid(True)
plt.show()

# scatter plot for Sale vs. RearCam
plt.figure(figsize=(10, 5))
plt.scatter(cell_data['RearCam'], cell_data['Sale'], color='red', label='Rear Cam')
plt.title('Sale vs. Rear Cam')
plt.xlabel('Rear Cam')
plt.ylabel('Sale')
plt.legend()
plt.grid(True)
plt.show()

"""A scatter plot of "Sales" vs. "Front Cam" and "Sales" vs. "Rear Cam" helps in predicting cellphone prices indirectly by providing insights into the preferences and priorities of consumers when purchasing cellphones."""

# Sort the data by "battery" for better visualization
cell_data.sort_values(by='battery', inplace=True)

# Create a line plot for Battery vs. Thickness
plt.figure(figsize=(10, 5))
plt.plot(cell_data['battery'], cell_data['thickness'], color='blue', marker='o', linestyle='-')
plt.title('Battery vs. Thickness')
plt.xlabel('Battery')
plt.ylabel('Thickness')
plt.grid(True)
plt.show()

data = cell_data.copy()
price_ranges = ['Budget', 'Mid-Range', 'Flagship']
data['Price Category'] = pd.cut(data['Price'], bins=[0, 1000, 3000, max(data['Price'])], labels=price_ranges)
avg_sales_by_price = data.groupby('Price Category')['Sale'].mean()
plt.figure(figsize=(10, 5))
avg_sales_by_price.plot(kind='bar', color='green')
plt.title('Average Sales by Price Category')
plt.xlabel('Price Category')
plt.ylabel('Average Sales')
plt.grid(axis='y')
plt.show()

""" prices below 1000 are categorized as "Low," prices between 1000 and 3000 are categorized as "Medium," and prices above 3000 are categorized as "High."""

# Create a scatter plot for CPU Frequency vs. RAM
plt.figure(figsize=(10, 6))
plt.scatter(data['cpu freq'], data['ram'], c=data['Price'], cmap='viridis', marker='o')
plt.title('CPU Frequency vs. RAM')
plt.xlabel('CPU Frequency (GHz)')
plt.ylabel('RAM (GB)')
plt.colorbar(label='Price')
plt.grid(True)
plt.show()

"""# APPLYING KNN"""

X = cell_data.drop(['Price', 'Product_id'], axis=1).values
y = cell_data['Price'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=100)

# Normalize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = KNeighborsClassifier(n_neighbors=5) #Selecting a Random K value
model.fit(X_train_scaled, y_train)
y_pred_knn = model.predict(X_test_scaled)
model_score = model.score(X_test_scaled, y_test)
model_score

print(f"Accuracy achieved by KNN model {round(model_score*100, 2)} %")

r2_knn = r2_score(y_test, y_pred_knn)
print("KNN Model:")
print(f"R-squared (R2) Score: {r2_knn}")

"""Hyperparameter tuning: KNeighborsClassifier"""

test_scores = []

neighbors = range(1, 21)

knn = KNeighborsClassifier()

for i in neighbors:
    knn.set_params(n_neighbors = i)

    knn.fit(X_train, y_train)

    test_scores.append(knn.score(X_test, y_test))

plt.plot(neighbors, test_scores, label="Test Scores")
plt.xticks(np.arange(1, 21, 1))
plt.xlabel("Number of neighbors")
plt.ylabel("Model score")
plt.legend()

print(f"Maximum KNN score on the test data: {max(test_scores)*100:.2f}%")

knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
print(f'KNN Model Score: {round(knn.score(X_test, y_test) * 100, 2)} %')

r2_knn = r2_score(y_test, y_pred)
rmse_knn = np.sqrt(mean_squared_error(y_test, y_pred))
print("KNN Model:")
print(f"R-squared (R2) Score: {r2_knn}")
print(f"RMSE score: {rmse_knn}")

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred, color='blue', marker='o')
plt.title('KNN Model: Actual vs. Predicted Price')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.grid(True)

"""# Applying Linear Regression"""

# Separate features (X) and target variable (y)
X = cell_data.drop('Price', axis=1)
y = cell_data['Price']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the MinMaxScaler and fit_transform on training set
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Use the same scaler to transform the test set
X_test_scaled = scaler.transform(X_test)

# Initialize the linear regression model
l_r = LinearRegression()

# Train the model on the scaled training set
mod1 = l_r.fit(X_train_scaled, y_train)

# Make predictions on the scaled test set
y_pred_lr_scaled = l_r.predict(X_test_scaled)
# Evaluate the model
r2_lr = r2_score(y_test, y_pred_lr_scaled)
mse_lr = mean_squared_error(y_test, y_pred_lr_scaled)
print(f'R-squared: {r2_lr}')
print(f'Mean Squared Error: {mse_lr}')

from yellowbrick.regressor import PredictionError

visualizer = PredictionError(mod1)
visualizer.score(X_test_scaled, y_test)
visualizer.show()

"""# Regression Tree"""

# Initialize the decision tree regressor
tree_model = DecisionTreeRegressor(random_state=42)

# Train the decision tree model
mod2 = tree_model.fit(X_train_scaled, y_train)

# Make predictions on the test set
y_pred_tree = tree_model.predict(X_test_scaled)

# Evaluate the model
r2_tree = r2_score(y_test, y_pred_tree)
print(f'R-squared: {r2_tree}')
mse_tree = mean_squared_error(y_test, y_pred_tree)
print(f'Mean Squared Error: {mse_tree}')

from yellowbrick.regressor import PredictionError

visualizer = PredictionError(mod2)
visualizer.score(X_test_scaled, y_test)
visualizer.show()

"""# Applying PCA With Linear Regression"""

pca = PCA(n_components=5)  # Selecting a random n_component value
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Train a linear regression model on the reduced feature set
model = LinearRegression()
mod3 = model.fit(X_train_pca, y_train)

# Make predictions on the test set
y_pred_pca = model.predict(X_test_pca)

# Evaluate the model

r2 = r2_score(y_test, y_pred_pca)
print(f'R-squared: {r2}')
mse = mean_squared_error(y_test, y_pred_pca)
print(f'Mean Squared Error: {mse}')

from yellowbrick.regressor import PredictionError

visualizer = PredictionError(mod3)
visualizer.score(X_test_pca, y_test)
visualizer.show()

"""**Checking for best n_component value using explained variance ratio**"""

# Define a list of n_components values to try
n_components_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]

explained_variances = []

for n_components in n_components_values:
    pca = PCA(n_components=n_components)
    pca.fit(X_train_scaled)
    explained_variances.append(np.sum(pca.explained_variance_ratio_))

plt.figure(figsize=(10, 6))
plt.plot(n_components_values, explained_variances, marker='o', linestyle='-')
plt.xlabel('Number of Components (n_components)')
plt.ylabel('Explained Variance Ratio')
plt.title('PCA Explained Variance vs. Number of Components')
plt.grid(True)


target_variance_ratio = 0.95

# Find the best n_components value that achieves or exceeds the target variance ratio
selected_n_components = None
for n_components, explained_variance in zip(n_components_values, explained_variances):
    if explained_variance >= target_variance_ratio:
        selected_n_components = n_components
        break

if selected_n_components is not None:
    print(f"Selected n_components: {selected_n_components}")
else:
    print("No n_components value achieved the target explained variance ratio.")

plt.show()

pca = PCA(selected_n_components)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

pca_lr = LinearRegression()
mod3 = model.fit(X_train_pca, y_train)


y_pred_pca = model.predict(X_test_pca)

from yellowbrick.regressor import PredictionError

visualizer = PredictionError(mod3)
visualizer.score(X_test_pca, y_test)
visualizer.show()

# Evaluate the model

r2_pca = r2_score(y_test, y_pred_pca)

print(f'R-squared: {r2_pca}')
mse_pca = mean_squared_error(y_test, y_pred_pca)
print(f'Mean Squared Error: {mse}')

"""# Applying Neural Network"""

# Extract the target variable 'Price'
target_column = 'Price'
y = cell_data[target_column]

# Extract features and drop unnecessary columns
X = cell_data.drop([target_column, 'Product_id'], axis=1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the neural network model
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='linear'))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)

# Evaluate the model
y_pred = model.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# Visualize training history
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Mean Squared Error')
plt.title('Training History')
plt.legend()
plt.show()

"""Scaling The Target variables to improve model performance"""

from tensorflow.keras.optimizers import Adam
# Normalize the target variable
scaler_y = StandardScaler()
y_train_scaled = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1))
y_test_scaled = scaler_y.transform(np.array(y_test).reshape(-1, 1))

# Build the neural network model
model_nn = Sequential()
model_nn.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))
model_nn.add(Dense(64, activation='relu'))
model_nn.add(Dense(1, activation='linear'))

# Compile the model with a lower learning rate
model_nn.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')

# Train the model
history = model_nn.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_scaled), verbose=1)

# Invert scaling for predictions
y_pred_scaled = model_nn.predict(X_test_scaled)
y_pred_nn = scaler_y.inverse_transform(y_pred_scaled)

# Evaluate the model
mse_nn = mean_squared_error(y_test, y_pred_nn)
r2_nn = r2_score(y_test, y_pred_nn)

print(f'Mean Squared Error: {mse_nn}')
print(f'R-squared: {r2_nn}')

# Visualize training history
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Mean Squared Error')
plt.title('Training History')
plt.legend()
plt.show()

# Evaluate and compare R-squared scores
plt.figure(figsize=(10, 5))
model_names = ['KNN', 'Linear Regression', 'Regression Tree', 'Linear Regression with PCA', 'Neural Network']
r2_scores = [r2_knn, r2_lr, r2_tree, r2_pca, r2_nn]
model_list = [knn, l_r, tree_model, pca_lr, model_nn]
# Create a bar graph
plt.bar(model_names, r2_scores, color=['blue', 'green', 'orange', 'red', 'purple'])
plt.xlabel('Models')
plt.ylabel('R-squared Score')
plt.title('Comparison of R-squared Scores')
plt.ylim(0, 1)  # Set the y-axis range if needed
plt.show()

max_idx = r2_scores.index((max(r2_scores)))

print(f"Highest R2 Score Among all models is of {model_names[max_idx]}: {round(max(r2_scores),4)}")

pred_model = model_list[max_idx]

"""Hence we can say that neural network is the best model to do the predictions for this task

Making Prediction with model having highest r2 score i.e. Neural Network by feeding custom values
"""

custom_input = np.array([[10,	135,	5.2,	424,	8,	1.35,	16,	3,	13,	8,	2610,	7.4]])   # Custom input values
custom_input_scaled = scaler.transform(custom_input)
custom_output_scaled = pred_model.predict(custom_input_scaled) # Make predictions
custom_output = scaler_y.inverse_transform(custom_output_scaled) # Invert scaling to get the final predicted price
print(f'Predicted Price: {custom_output[0][0]}')

"""# Applying Our Model To Self made Custom dataset

We've created a custom dataset with 14 features and 59 rows to test our model's performance and predictability
"""

custom_data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Cellphone_custome.csv")

custom_data.head()

custom_data.shape

Price_val = custom_data['Price'].values

X = custom_data.drop(['Product_id', 'Price'], axis = 1)

predicted_prices = []
for i in range(59):
  custom_input = X.values[i].reshape(1, -1)   # Custom input values
  custom_input_scaled = scaler.transform(custom_input)
  custom_output_scaled = pred_model.predict(custom_input_scaled) # Make predictions
  custom_output = scaler_y.inverse_transform(custom_output_scaled) # Invert scaling to get the final predicted price
  predicted_prices.append(custom_output[0][0])
  print(f'Predicted Price: {custom_output[0][0]}')

# Evaluate the model
mse = mean_squared_error(Price_val, predicted_prices)
r2 = r2_score(Price_val, predicted_prices)
print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

plt.figure(figsize=(10, 6))

plt.scatter(Price_val, predicted_prices, alpha=0.5)
plt.title('Actual vs. Predicted Prices')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.show()

# Plotting the accuracy curve
plt.figure(figsize=(10, 6))
plt.plot(Price_val, label='Actual Prices', color='blue')
plt.plot(predicted_prices, label='Predicted Prices', color='red')
plt.title('Actual vs. Predicted Prices over Data Points')
plt.xlabel('Data Points')
plt.ylabel('Prices')
plt.legend()
plt.show()

"""Model's Accuracy"""

threshold = 15
percentage_diff = np.abs((Price_val - predicted_prices) / Price_val) * 100
correct_predictions = np.sum(percentage_diff <= threshold)
accuracy = correct_predictions / len(Price_val) * 100
print(f'Accuracy On Custom Dataset: {accuracy:.2f}%')

"""# **END OF ASSIGNMENT**"""